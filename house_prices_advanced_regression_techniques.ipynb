{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2T/I491A2oiqFx6tXXw7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/molefimcm/my-colab-notebooks/blob/main/house_prices_advanced_regression_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9gFRxzUfTyd"
      },
      "outputs": [],
      "source": [
        "# House Prices Project - Advanced Regression Techniques\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the folder defined by variables \"/content/drive/MyDrive/MAIN_DIR/MAIN_DIR/PROJECT_NAME/INPUT_SUBDIR\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "MAIN_DIR = 'Notebook_Data'\n",
        "PROJECT_NAME = 'house_price_prediction'\n",
        "INPUT_SUBDIR = 'input'\n",
        "INPUT_DIR = os.path.join('/content/drive/MyDrive', MAIN_DIR, PROJECT_NAME, INPUT_SUBDIR)\n",
        "OUTPUT_SUBDIR = 'output'\n",
        "OUTPUT_DIR = os.path.join('/content/drive/MyDrive', MAIN_DIR, PROJECT_NAME, OUTPUT_SUBDIR)\n",
        "# Now you can use INPUT_DIR to access your files\n",
        "print(os.listdir(INPUT_DIR))\n",
        "\n",
        "# Load the data\n",
        "train = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n",
        "print(f\"Training set shape: {train.shape}\")\n",
        "print(f\"Testing set shape: {test.shape}\")\n",
        "\n",
        "# Save the ID column for submission file\n",
        "train_ID = train['Id']\n",
        "test_ID = test['Id']\n",
        "\n",
        "# Remove the ID column from the datasets\n",
        "train.drop('Id', axis=1, inplace=True)\n",
        "test.drop('Id', axis=1, inplace=True)\n",
        "\n",
        "# Log transform the target for better model performance\n",
        "y_train = np.log1p(train['SalePrice'])\n",
        "\n",
        "# Combine train and test for preprocessing\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "all_data = pd.concat([train.drop('SalePrice', axis=1), test])\n",
        "\n",
        "# Handle missing values by feature type\n",
        "# For categorical features with high missingness, create a 'None' category\n",
        "for col in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType',\n",
        "           'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'BsmtCond',\n",
        "           'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType']:\n",
        "    all_data[col] = all_data[col].fillna('None')\n",
        "\n",
        "# For features where NA means 0\n",
        "for col in ['GarageYrBlt', 'GarageArea', 'GarageCars', 'BsmtFinSF1', 'BsmtFinSF2',\n",
        "           'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'MasVnrArea']:\n",
        "    all_data[col] = all_data[col].fillna(0)\n",
        "\n",
        "# For Lot Frontage, use median by neighborhood\n",
        "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
        "    lambda x: x.fillna(x.median()))\n",
        "\n",
        "# Fill remaining numerical NA with median\n",
        "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
        "for col in numeric_cols:\n",
        "    all_data[col] = all_data[col].fillna(all_data[col].median())\n",
        "\n",
        "# Fill remaining categorical NA with mode\n",
        "categorical_cols = all_data.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
        "\n",
        "# Feature Engineering\n",
        "# Create new features\n",
        "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
        "all_data['TotalBath'] = all_data['FullBath'] + (0.5 * all_data['HalfBath']) + \\\n",
        "                        all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath'])\n",
        "all_data['HasPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_data['Has2ndFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_data['HasGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_data['HasBsmt'] = all_data['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_data['HasFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_data['YearsSinceBuilt'] = 2023 - all_data['YearBuilt']\n",
        "all_data['YearsSinceRemod'] = 2023 - all_data['YearRemodAdd']\n",
        "all_data['TotalPorchSF'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + \\\n",
        "                           all_data['3SsnPorch'] + all_data['ScreenPorch']\n",
        "\n",
        "# Label encoding for ordinal features\n",
        "ordinal_features = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC',\n",
        "                   'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
        "\n",
        "quality_mapping = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
        "for feature in ordinal_features:\n",
        "    all_data[feature] = all_data[feature].map(quality_mapping)\n",
        "\n",
        "# Fix skewed numerical features\n",
        "numeric_feats = all_data.dtypes[all_data.dtypes != 'object'].index\n",
        "skewed_feats = all_data[numeric_feats].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
        "high_skew = skewed_feats[skewed_feats > 0.5]\n",
        "\n",
        "# Apply Box-Cox transform to highly skewed features\n",
        "from scipy.special import boxcox1p\n",
        "for feature in high_skew.index:\n",
        "    all_data[feature] = boxcox1p(all_data[feature], 0.15)\n",
        "\n",
        "# One-hot encode categorical features\n",
        "all_data = pd.get_dummies(all_data)\n",
        "\n",
        "# Splitting the data back to train and test\n",
        "X_train = all_data[:ntrain]\n",
        "X_test = all_data[ntrain:]\n",
        "\n",
        "# Base Models for Model Averaging\n",
        "models = {\n",
        "    'Ridge': Ridge(alpha=10),\n",
        "    'Lasso': Lasso(alpha=0.001),\n",
        "    'ElasticNet': ElasticNet(alpha=0.001, l1_ratio=0.5),\n",
        "    'GBR': GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=4,\n",
        "                                    max_features='sqrt', min_samples_leaf=15,\n",
        "                                    min_samples_split=10, random_state=42),\n",
        "    'XGBoost': xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=4,\n",
        "                               min_child_weight=0.5, gamma=0.9, subsample=0.8,\n",
        "                               colsample_bytree=0.8, objective='reg:squarederror',\n",
        "                               nthread=-1, scale_pos_weight=1, seed=42),\n",
        "    'LightGBM': lgb.LGBMRegressor(objective='regression', num_leaves=31, learning_rate=0.05,\n",
        "                                 n_estimators=500, max_bin=255, bagging_fraction=0.8,\n",
        "                                 bagging_freq=5, feature_fraction=0.8, feature_fraction_seed=42,\n",
        "                                 bagging_seed=42, min_data_in_leaf=6, min_sum_hessian_in_leaf=11)\n",
        "}\n",
        "\n",
        "# Store the models' predictions\n",
        "model_preds = {}\n",
        "\n",
        "# Train each model and make predictions\n",
        "for name, model in models.items():\n",
        "    # Fit on all training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    model_preds[name] = np.expm1(model.predict(X_test))  # Reverse log transformation\n",
        "    print(f\"{name} model trained and predictions made\")\n",
        "\n",
        "# Weighted averaging of models\n",
        "ensemble_pred = np.zeros(ntest)\n",
        "weights = {\n",
        "    'Ridge': 0.15,\n",
        "    'Lasso': 0.15,\n",
        "    'ElasticNet': 0.1,\n",
        "    'GBR': 0.2,\n",
        "    'XGBoost': 0.2,\n",
        "    'LightGBM': 0.2\n",
        "}\n",
        "\n",
        "for name, pred in model_preds.items():\n",
        "    ensemble_pred += weights[name] * pred\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_ID,\n",
        "    'SalePrice': ensemble_pred\n",
        "})\n",
        "\n",
        "# Display the first few rows to verify format\n",
        "print(\"\\nSubmission file preview:\")\n",
        "print(submission.head())\n",
        "\n",
        "# For Google Colab - download the file\n",
        "from google.colab import files\n",
        "# Save to CSV\n",
        "submission.to_csv(os.path.join(OUTPUT_DIR, 'submission.csv'), index=False)\n",
        "# Download it\n",
        "files.download(os.path.join(OUTPUT_DIR, 'submission.csv'))\n",
        "print(\"\\nSubmission file created successfully with shape:\", submission.shape)\n"
      ]
    }
  ]
}